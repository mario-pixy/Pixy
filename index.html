<!doctype html>
<html lang="it">
<head>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Pixy</title>
  <style>
    body{
      margin:0;
      background:#000;
      display:flex;
      justify-content:center;
      align-items:center;
      height:100vh;
      overflow:hidden;
      user-select:none;
      -webkit-user-select:none;
      -webkit-touch-callout:none;
    }
    #face{
      display:flex;
      flex-direction:row;
      align-items:center;
    }
    .eye{
      width:90px;
      height:90px;
      background:cyan;
      margin:25px;
      border-radius:20px;
      box-shadow:0 0 50px cyan;
      transition:all .2s ease;
    }
    .speaking .eye{
      height:120px;
      box-shadow:0 0 80px cyan;
    }
    .listening .eye{
      height:60px;
      box-shadow:0 0 90px cyan;
      transform:scaleX(1.2);
    }

    /* Debug (puoi spegnerlo via JS: DEBUG=false) */
    #debug{
      position:fixed;
      left:12px; right:12px; bottom:18px;
      color:#fff;
      font:14px -apple-system,system-ui;
      opacity:.9;
      pointer-events:none;
    }
    #last{ margin-top:6px; white-space:pre-wrap; }
  </style>
</head>
<body>

  <div id="face">
    <div class="eye"></div>
    <div class="eye"></div>
  </div>

  <div id="debug">
    <div id="status">Stato: idle</div>
    <div id="last"></div>
  </div>

<script>
  // ====== CONFIG ======
  const DEBUG = true;          // metti false per togliere scritte
  const AUTO_LISTEN = true;    // dopo che parla, torna in ascolto
  const AUTO_LISTEN_DELAY = 450;

  // ====== DOM ======
  const face = document.getElementById("face");
  const statusEl = document.getElementById("status");
  const lastEl = document.getElementById("last");
  const debugBox = document.getElementById("debug");
  if(!DEBUG) debugBox.style.display = "none";

  function setState(state){
    face.classList.remove("listening","speaking");
    if(state==="listening") face.classList.add("listening");
    if(state==="speaking") face.classList.add("speaking");
    if(DEBUG) statusEl.textContent = "Stato: " + state;
  }

  // ====== iOS Audio unlock (serve un TAP) ======
  let audioUnlocked = false;
  function unlockAudio(){
    if(audioUnlocked) return;
    audioUnlocked = true;

    // sblocca speechSynthesis
    try{
      window.speechSynthesis.cancel();
      const u = new SpeechSynthesisUtterance(" ");
      u.volume = 0;
      window.speechSynthesis.speak(u);
      window.speechSynthesis.cancel();
    }catch(e){}
  }

  // ====== TTS ======
  function speak(text){
    unlockAudio();

    const msg = (text || "").trim() || "Ok.";
    setState("speaking");

    // tick per iOS
    setTimeout(() => {
      try{
        window.speechSynthesis.cancel();
        const u = new SpeechSynthesisUtterance(msg);
        u.lang = "it-IT";
        u.rate = 1.0;
        u.pitch = 1.05;
        u.volume = 1;

        u.onend = () => {
          setState("idle");
          if(AUTO_LISTEN) {
            setTimeout(() => startListening(true), AUTO_LISTEN_DELAY);
          }
        };
        u.onerror = () => {
          setState("idle");
          if(AUTO_LISTEN) {
            setTimeout(() => startListening(true), AUTO_LISTEN_DELAY);
          }
        };

        window.speechSynthesis.speak(u);
      }catch(e){
        setState("idle");
        if(DEBUG) lastEl.textContent = "ERRORE TTS: " + e;
      }
    }, 50);
  }

  // ====== Reply cleaning (toglie la frase fastidiosa) ======
  function cleanReply(reply){
    if(!reply) return "";
    return reply
      .replace(/\s+$/g, "")
      .replace(/(come posso aiutarti oggi\??)\s*$/i, "")
      .replace(/(come posso aiutarti\??)\s*$/i, "")
      .trim();
  }

  // ====== Call server (/api/chat) ======
  async function sendToPixy(text){
    try{
      if(DEBUG) lastEl.textContent = "Tu: " + text;
      setState("speaking");

      const r = await fetch("/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ text })
      });

      const ct = r.headers.get("content-type") || "";
      if(!ct.includes("application/json")){
        const raw = await r.text();
        setState("idle");
        if(DEBUG) lastEl.textContent = "ERRORE: risposta non JSON\n" + raw.slice(0, 250);
        return;
      }

      const data = await r.json();
      const replyRaw = (data.text || "").trim();
      const reply = cleanReply(replyRaw);

      if(DEBUG) lastEl.textContent = "Tu: " + text + "\nPixy: " + (reply || "(risposta vuota)");
      speak(reply || "Ok.");

    }catch(e){
      setState("idle");
      if(DEBUG) lastEl.textContent = "ERRORE: " + e;
    }
  }

  // ====== Speech Recognition ======
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  let recognition = null;
  let isListening = false;

  function stopListening(){
    try{
      if(recognition && isListening) recognition.stop();
    }catch(e){}
    isListening = false;
  }

  function startListening(fromAuto=false){
    // Non avviare ascolto mentre sta parlando
    if(face.classList.contains("speaking")) return;

    unlockAudio();

    // Su iPhone Safari spesso SR non esiste: fallback testo
    if(!SR){
      // se parte da auto, non spammo prompt. Chiedo solo se toccano.
      if(fromAuto) return;
      const t = prompt("Scrivi a Pixy:");
      if(t && t.trim()) sendToPixy(t.trim());
      return;
    }

    if(!recognition){
      recognition = new SR();
      recognition.lang = "it-IT";
      recognition.interimResults = false;
      recognition.continuous = false;

      recognition.onstart = () => {
        isListening = true;
        setState("listening");
      };

      recognition.onend = () => {
        isListening = false;
        if(!face.classList.contains("speaking")) setState("idle");
      };

      recognition.onerror = (e) => {
        isListening = false;
        setState("idle");
        if(DEBUG) lastEl.textContent = "ERRORE MIC/ASR: " + (e.error || "sconosciuto");

        // fallback testuale SOLO se Ã¨ stato un tap utente
        if(!fromAuto){
          const t = prompt("Non riesco a sentire. Scrivi a Pixy:");
          if(t && t.trim()) sendToPixy(t.trim());
        }
      };

      recognition.onresult = (event) => {
        const spoken = event.results?.[0]?.[0]?.transcript || "";
        const t = spoken.trim();
        if(t) sendToPixy(t);
        else if(!fromAuto){
          const x = prompt("Non ho capito. Scrivi a Pixy:");
          if(x && x.trim()) sendToPixy(x.trim());
        }
      };
    }

    // evita start doppio
    if(isListening) return;

    try{
      recognition.start();
    }catch(e){
      // Safari a volte lancia error se start consecutivi
      isListening = false;
      setState("idle");
    }
  }

  // ====== TAP ======
  // Primo tap: sblocca audio e avvia ascolto (obbligatorio su iOS)
  document.body.addEventListener("click", () => startListening(false));

  setState("idle");
</script>

</body>
</html>
